---
---

<br>
<br>

<div align="center">
  <table class="row">
    <tr>
    <td style="text-align: center"><img src="https://www.zupimages.net/up/23/14/f20e.png" style="width:200px;height:200px;"></td>
  </tr>
  <tr>
    <td style="text-align: center"><b>Jeff Clune</b></td>
  </tr>
  <tr>
    <td style="text-align: center">speaker</td>
  </tr>
  </table>
</div>



###### Bio


Jeff Clune is an Associate Professor of Computer Science at the University of British Columbia, a Canada CIFAR AI Chair and Faculty Member at the Vector Institute, and a Senior Research Advisor at DeepMind.
<br>
<br>
Previously, he was a Research Team Leader at OpenAI. Before that he was a Senior Research Manager and founding member of Uber AI Labs. Prior to Uber, he was the Loy and Edith Harris Associate Professor in Computer Science at the University of Wyoming.
<br><br>
He conducts research in three related areas of machine learning : Deep Learning, Evolving Neural Networks, and Robotics. 
<br>
<br>
<a href="https://scholar.google.com/citations?user=5TZ7f5wAAAAJ&hl=fr&oi=ao/">Google scholar page</a> &bull; <a href="http://jeffclune.com/index.html/">Personal webpage</a>

<br>
<br>


###### Talk


<div align="center">
	<b>Open-ended and AI-generating Algorithms in the Era of Foundation Models</b>
</div>

Foundation models (e.g. large language models) create exciting new opportunities in our longstanding quests to produce open-ended and AI-generating algorithms. In this talk I will share some of our recent work harnessing the power of foundation models to make progress in these areas. I will cover three of our more recent papers: (1) OMNI: Open-endedness via Models of human Notions of Interestingness, (2) Video Pre-Training (VPT), and (3) Thought Cloning: Learning to Think while Acting by Imitating Human Thinking. 




<br>
<br>
<br>
<br>




<div align="center">
	<a href="https://imolconf2023.github.io/">Home</a>
</div>

<br>
<br>

